"""
Production-Grade Infrastructure as Code Generator
Supports Terraform, Pulumi, CloudFormation with advanced validation
"""

import asyncio
import json
import subprocess
import tempfile
import os
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import logging

from ...config.settings import settings


class IaCProvider(str, Enum):
    TERRAFORM = "terraform"
    PULUMI = "pulumi"
    CLOUDFORMATION = "cloudformation"
    BICEP = "bicep"


class IaCValidationLevel(str, Enum):
    BASIC = "basic"
    STANDARD = "standard"
    STRICT = "strict"


@dataclass
class IaCResource:
    name: str
    type: str
    provider: str
    configuration: Dict[str, Any]
    estimated_cost: float
    security_risks: List[str]
    compliance_issues: List[str]


@dataclass
class IaCValidationResult:
    is_valid: bool
    errors: List[str]
    warnings: List[str]
    security_issues: List[str]
    compliance_violations: List[str]
    cost_estimate: float
    deployment_time: str


class IaCGenerator:
    """Production-grade Infrastructure as Code generator"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.supported_providers = {
            IaCProvider.TERRAFORM: self._generate_terraform,
            IaCProvider.PULUMI: self._generate_pulumi,
            IaCProvider.CLOUDFORMATION: self._generate_cloudformation,
            IaCProvider.BICEP: self._generate_bicep
        }
        
        # Security scanning tools
        self.security_scanners = {
            "checkov": self._run_checkov_scan,
            "tfsec": self._run_tfsec_scan,
            "trivy": self._run_trivy_scan
        }
        
        # Cost estimation models
        self.cost_estimators = {
            "aws": self._estimate_aws_cost,
            "azure": self._estimate_azure_cost,
            "gcp": self._estimate_gcp_cost
        }
    
    async def generate_infrastructure(
        self,
        requirements: Dict[str, Any],
        provider: IaCProvider = IaCProvider.TERRAFORM,
        validation_level: IaCValidationLevel = IaCValidationLevel.STRICT
    ) -> Dict[str, Any]:
        """Generate complete infrastructure as code"""
        
        try:
            self.logger.info(f"Generating {provider.value} infrastructure")
            
            # Generate IaC code
            iac_code = await self.supported_providers[provider](requirements)
            
            # Validate the generated code
            validation_result = await self._validate_iac(
                iac_code, 
                provider, 
                validation_level
            )
            
            # Estimate costs
            cost_estimate = await self._estimate_costs(iac_code, requirements)
            
            # Security analysis
            security_analysis = await self._analyze_security(iac_code, provider)
            
            # Generate deployment plan
            deployment_plan = await self._generate_deployment_plan(
                iac_code, 
                requirements
            )
            
            return {
                "provider": provider.value,
                "iac_code": iac_code,
                "validation": validation_result,
                "cost_estimate": cost_estimate,
                "security_analysis": security_analysis,
                "deployment_plan": deployment_plan,
                "resources": await self._extract_resources(iac_code, provider),
                "estimated_deployment_time": self._estimate_deployment_time(requirements)
            }
            
        except Exception as e:
            self.logger.error(f"IaC generation failed: {str(e)}")
            raise
    
    async def _generate_terraform(self, requirements: Dict[str, Any]) -> Dict[str, str]:
        """Generate comprehensive Terraform configuration"""
        
        # Main configuration
        main_tf = f"""
# Generated by AI Ops Guardian Angel
terraform {{
  required_version = ">= 1.0"
  required_providers {{
    aws = {{
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }}
    azurerm = {{
      source  = "hashicorp/azurerm"
      version = "~> 3.0"
    }}
    google = {{
      source  = "hashicorp/google"
      version = "~> 4.0"
    }}
  }}
}}

# Provider configurations
{self._generate_provider_configs(requirements)}

# VPC/Network Configuration
{self._generate_network_config(requirements)}

# Compute Resources
{self._generate_compute_config(requirements)}

# Storage Resources
{self._generate_storage_config(requirements)}

# Database Resources
{self._generate_database_config(requirements)}

# Load Balancer Configuration
{self._generate_lb_config(requirements)}

# Security Groups and Firewall Rules
{self._generate_security_config(requirements)}

# Monitoring and Logging
{self._generate_monitoring_config(requirements)}

# Backup and Disaster Recovery
{self._generate_backup_config(requirements)}
"""
        
        # Variables file
        variables_tf = f"""
variable "environment" {{
  description = "Environment name"
  type        = string
  default     = "{requirements.get('environment', 'production')}"
}}

variable "project_name" {{
  description = "Project name"
  type        = string
  default     = "{requirements.get('project_name', 'ai-ops-platform')}"
}}

variable "aws_region" {{
  description = "AWS region"
  type        = string
  default     = "{requirements.get('aws_region', 'us-east-1')}"
}}

variable "vpc_cidr" {{
  description = "VPC CIDR block"
  type        = string
  default     = "{requirements.get('vpc_cidr', '10.0.0.0/16')}"
}}

variable "availability_zones" {{
  description = "Availability zones"
  type        = list(string)
  default     = {requirements.get('availability_zones', ['us-east-1a', 'us-east-1b'])}
}}

variable "instance_type" {{
  description = "EC2 instance type"
  type        = string
  default     = "{requirements.get('instance_type', 't3.medium')}"
}}

variable "db_instance_class" {{
  description = "RDS instance class"
  type        = string
  default     = "{requirements.get('db_instance_class', 'db.t3.micro')}"
}}
"""
        
        # Outputs file
        outputs_tf = f"""
output "vpc_id" {{
  description = "VPC ID"
  value       = aws_vpc.main.id
}}

output "public_subnet_ids" {{
  description = "Public subnet IDs"
  value       = aws_subnet.public[*].id
}}

output "private_subnet_ids" {{
  description = "Private subnet IDs"
  value       = aws_subnet.private[*].id
}}

output "load_balancer_dns" {{
  description = "Load balancer DNS name"
  value       = aws_lb.main.dns_name
}}

output "database_endpoint" {{
  description = "Database endpoint"
  value       = aws_db_instance.main.endpoint
}}

output "monitoring_dashboard_url" {{
  description = "Monitoring dashboard URL"
  value       = "https://console.aws.amazon.com/cloudwatch/home?region=${{var.aws_region}}"
}}
"""
        
        return {
            "main.tf": main_tf,
            "variables.tf": variables_tf,
            "outputs.tf": outputs_tf,
            "versions.tf": self._generate_versions_tf(),
            "README.md": self._generate_terraform_readme(requirements)
        }
    
    async def _generate_pulumi(self, requirements: Dict[str, Any]) -> str:
        """Generate Pulumi TypeScript configuration"""
        
        return f"""
import * as pulumi from "@pulumi/pulumi";
import * as aws from "@pulumi/aws";
import * as azure from "@pulumi/azure";
import * as gcp from "@pulumi/gcp";

// Configuration
const config = new pulumi.Config();
const environment = config.require("environment");
const projectName = config.require("projectName");

// AWS Resources
const vpc = new aws.ec2.Vpc("{requirements.get('project_name', 'ai-ops-platform')}-vpc", {{
    cidrBlock: "{requirements.get('vpc_cidr', '10.0.0.0/16')}",
    enableDnsHostnames: true,
    enableDnsSupport: true,
    tags: {{
        Name: `${{projectName}}-vpc`,
        Environment: environment,
        ManagedBy: "pulumi"
    }}
}});

// Public Subnets
const publicSubnets = [];
for (let i = 0; i < {len(requirements.get('availability_zones', ['us-east-1a', 'us-east-1b']))}; i++) {{
    const subnet = new aws.ec2.Subnet(`public-subnet-${{i}}`, {{
        vpcId: vpc.id,
        cidrBlock: `10.0.${{i}}.0/24`,
        availabilityZone: "{requirements.get('availability_zones', ['us-east-1a', 'us-east-1b'])[0]}",
        mapPublicIpOnLaunch: true,
        tags: {{
            Name: `${{projectName}}-public-subnet-${{i}}`,
            Environment: environment
        }}
    }});
    publicSubnets.push(subnet);
}}

// Security Group
const webSecurityGroup = new aws.ec2.SecurityGroup("web-sg", {{
    vpcId: vpc.id,
    description: "Web security group",
    ingress: [
        {{
            protocol: "tcp",
            fromPort: 80,
            toPort: 80,
            cidrBlocks: ["0.0.0.0/0"]
        }},
        {{
            protocol: "tcp",
            fromPort: 443,
            toPort: 443,
            cidrBlocks: ["0.0.0.0/0"]
        }}
    ],
    egress: [
        {{
            protocol: "-1",
            fromPort: 0,
            toPort: 0,
            cidrBlocks: ["0.0.0.0/0"]
        }}
    ],
    tags: {{
        Name: `${{projectName}}-web-sg`,
        Environment: environment
    }}
}});

// Application Load Balancer
const alb = new aws.lb.LoadBalancer("main-alb", {{
    internal: false,
    loadBalancerType: "application",
    securityGroups: [webSecurityGroup.id],
    subnets: publicSubnets.map(subnet => subnet.id),
    enableDeletionProtection: false,
    tags: {{
        Name: `${{projectName}}-alb`,
        Environment: environment
    }}
}});

// Target Group
const targetGroup = new aws.lb.TargetGroup("main-tg", {{
    port: 80,
    protocol: "HTTP",
    vpcId: vpc.id,
    healthCheck: {{
        enabled: true,
        healthyThreshold: 2,
        interval: 30,
        matcher: "200",
        path: "/health",
        port: "traffic-port",
        protocol: "HTTP",
        timeout: 5,
        unhealthyThreshold: 2
    }},
    tags: {{
        Name: `${{projectName}}-tg`,
        Environment: environment
    }}
}});

// Listener
const listener = new aws.lb.Listener("main-listener", {{
    loadBalancerArn: alb.arn,
    port: 80,
    protocol: "HTTP",
    defaultActions: [{{
        type: "forward",
        targetGroupArn: targetGroup.arn
    }}]
}});

// RDS Database
const dbSubnetGroup = new aws.rds.SubnetGroup("main-db-subnet-group", {{
    subnetIds: publicSubnets.map(subnet => subnet.id),
    tags: {{
        Name: `${{projectName}}-db-subnet-group`,
        Environment: environment
    }}
}});

const dbInstance = new aws.rds.Instance("main-db", {{
    allocatedStorage: 20,
    engine: "postgres",
    engineVersion: "13.7",
    instanceClass: "{requirements.get('db_instance_class', 'db.t3.micro')}",
    dbName: "aiopsdb",
    username: "admin",
    password: config.requireSecret("dbPassword"),
    skipFinalSnapshot: true,
    dbSubnetGroupName: dbSubnetGroup.name,
    vpcSecurityGroupIds: [webSecurityGroup.id],
    tags: {{
        Name: `${{projectName}}-db`,
        Environment: environment
    }}
}});

// Outputs
export const vpcId = vpc.id;
export const publicSubnetIds = publicSubnets.map(subnet => subnet.id);
export const loadBalancerDns = alb.dnsName;
export const databaseEndpoint = dbInstance.endpoint;
"""
    
    async def _validate_iac(
        self, 
        iac_code: Dict[str, str], 
        provider: IaCProvider,
        validation_level: IaCValidationLevel
    ) -> IaCValidationResult:
        """Validate generated IaC code"""
        
        errors = []
        warnings = []
        security_issues = []
        compliance_violations = []
        
        try:
            # Create temporary directory for validation
            with tempfile.TemporaryDirectory() as temp_dir:
                # Write IaC files
                for filename, content in iac_code.items():
                    if filename.endswith('.tf') or filename.endswith('.ts'):
                        filepath = Path(temp_dir) / filename
                        filepath.write_text(content)
                
                # Run provider-specific validation
                if provider == IaCProvider.TERRAFORM:
                    validation_result = await self._validate_terraform(temp_dir, validation_level)
                elif provider == IaCProvider.PULUMI:
                    validation_result = await self._validate_pulumi(temp_dir, validation_level)
                else:
                    validation_result = IaCValidationResult(
                        is_valid=True,
                        errors=[],
                        warnings=[],
                        security_issues=[],
                        compliance_violations=[],
                        cost_estimate=0.0,
                        deployment_time="5 minutes"
                    )
                
                return validation_result
                
        except Exception as e:
            self.logger.error(f"IaC validation failed: {str(e)}")
            return IaCValidationResult(
                is_valid=False,
                errors=[f"Validation failed: {str(e)}"],
                warnings=[],
                security_issues=[],
                compliance_violations=[],
                cost_estimate=0.0,
                deployment_time="Unknown"
            )
    
    async def _validate_terraform(self, temp_dir: str, validation_level: IaCValidationLevel) -> IaCValidationResult:
        """Validate Terraform configuration"""
        
        errors = []
        warnings = []
        security_issues = []
        compliance_violations = []
        
        try:
            # Initialize Terraform
            result = subprocess.run(
                ["terraform", "init"],
                cwd=temp_dir,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                errors.append(f"Terraform init failed: {result.stderr}")
            
            # Validate Terraform syntax
            result = subprocess.run(
                ["terraform", "validate"],
                cwd=temp_dir,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                errors.append(f"Terraform validation failed: {result.stderr}")
            
            # Run security scanning
            if validation_level in [IaCValidationLevel.STANDARD, IaCValidationLevel.STRICT]:
                security_result = await self._run_checkov_scan(temp_dir)
                security_issues.extend(security_result.get('issues', []))
                
                tfsec_result = await self._run_tfsec_scan(temp_dir)
                security_issues.extend(tfsec_result.get('issues', []))
            
            # Run compliance checks
            if validation_level == IaCValidationLevel.STRICT:
                compliance_result = await self._run_compliance_checks(temp_dir)
                compliance_violations.extend(compliance_result.get('violations', []))
            
            return IaCValidationResult(
                is_valid=len(errors) == 0,
                errors=errors,
                warnings=warnings,
                security_issues=security_issues,
                compliance_violations=compliance_violations,
                cost_estimate=await self._estimate_terraform_cost(temp_dir),
                deployment_time="10-15 minutes"
            )
            
        except Exception as e:
            self.logger.error(f"Terraform validation error: {str(e)}")
            return IaCValidationResult(
                is_valid=False,
                errors=[f"Validation error: {str(e)}"],
                warnings=[],
                security_issues=[],
                compliance_violations=[],
                cost_estimate=0.0,
                deployment_time="Unknown"
            )
    
    async def _run_checkov_scan(self, directory: str) -> Dict[str, Any]:
        """Run Checkov security scan"""
        try:
            result = subprocess.run(
                ["checkov", "-d", directory, "--output", "json"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                scan_results = json.loads(result.stdout)
                return {
                    "scanner": "checkov",
                    "issues": scan_results.get('results', {}).get('failed_checks', []),
                    "passed_checks": scan_results.get('results', {}).get('passed_checks', [])
                }
            else:
                return {"scanner": "checkov", "issues": [], "error": result.stderr}
                
        except Exception as e:
            return {"scanner": "checkov", "issues": [], "error": str(e)}
    
    async def _run_tfsec_scan(self, directory: str) -> Dict[str, Any]:
        """Run tfsec security scan"""
        try:
            result = subprocess.run(
                ["tfsec", directory, "--format", "json"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                scan_results = json.loads(result.stdout)
                return {
                    "scanner": "tfsec",
                    "issues": scan_results.get('results', []),
                    "passed_checks": []
                }
            else:
                return {"scanner": "tfsec", "issues": [], "error": result.stderr}
                
        except Exception as e:
            return {"scanner": "tfsec", "issues": [], "error": str(e)}
    
    async def _run_trivy_scan(self, directory: str) -> Dict[str, Any]:
        """Run Trivy security scan"""
        try:
            result = subprocess.run(
                ["trivy", "config", directory, "--format", "json"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                scan_results = json.loads(result.stdout)
                return {
                    "scanner": "trivy",
                    "issues": scan_results.get('results', []),
                    "passed_checks": []
                }
            else:
                return {"scanner": "trivy", "issues": [], "error": result.stderr}
                
        except Exception as e:
            return {"scanner": "trivy", "issues": [], "error": str(e)}
    
    async def _estimate_costs(self, iac_code: Dict[str, str], requirements: Dict[str, Any]) -> Dict[str, Any]:
        """Estimate infrastructure costs"""
        
        total_cost = 0.0
        cost_breakdown = {}
        
        # Estimate based on requirements
        if 'compute_instances' in requirements:
            instance_count = requirements['compute_instances'].get('count', 2)
            instance_type = requirements['compute_instances'].get('type', 't3.medium')
            instance_cost = self._get_instance_cost(instance_type)
            compute_cost = instance_count * instance_cost * 730  # Monthly hours
            cost_breakdown['compute'] = compute_cost
            total_cost += compute_cost
        
        if 'database' in requirements:
            db_type = requirements['database'].get('type', 'rds')
            db_instance = requirements['database'].get('instance_class', 'db.t3.micro')
            db_cost = self._get_database_cost(db_instance)
            cost_breakdown['database'] = db_cost
            total_cost += db_cost
        
        if 'storage' in requirements:
            storage_gb = requirements['storage'].get('size_gb', 100)
            storage_cost = storage_gb * 0.023  # S3 standard storage cost per GB
            cost_breakdown['storage'] = storage_cost
            total_cost += storage_cost
        
        if 'load_balancer' in requirements:
            lb_cost = 16.20  # ALB cost per month
            cost_breakdown['load_balancer'] = lb_cost
            total_cost += lb_cost
        
        return {
            "total_monthly_cost": total_cost,
            "cost_breakdown": cost_breakdown,
            "currency": "USD",
            "region": requirements.get('aws_region', 'us-east-1'),
            "provider": requirements.get('cloud_provider', 'aws')
        }
    
    def _get_instance_cost(self, instance_type: str) -> float:
        """Get hourly cost for instance type"""
        costs = {
            't3.micro': 0.0084,
            't3.small': 0.0168,
            't3.medium': 0.0336,
            't3.large': 0.0672,
            'm5.large': 0.096,
            'm5.xlarge': 0.192,
            'c5.large': 0.085,
            'c5.xlarge': 0.17
        }
        return costs.get(instance_type, 0.0336)
    
    def _get_database_cost(self, instance_class: str) -> float:
        """Get monthly cost for database instance"""
        costs = {
            'db.t3.micro': 12.41,
            'db.t3.small': 24.82,
            'db.t3.medium': 49.64,
            'db.m5.large': 171.60,
            'db.r5.large': 228.80
        }
        return costs.get(instance_class, 12.41)
    
    def _generate_provider_configs(self, requirements: Dict[str, Any]) -> str:
        """Generate provider configurations"""
        configs = []
        
        if 'aws' in requirements.get('providers', ['aws']):
            configs.append("""
provider "aws" {
  region = var.aws_region
  
  default_tags {
    tags = {
      Environment = var.environment
      Project     = var.project_name
      ManagedBy   = "terraform"
    }
  }
}
""")
        
        if 'azure' in requirements.get('providers', []):
            configs.append("""
provider "azurerm" {
  features {}
}
""")
        
        if 'gcp' in requirements.get('providers', []):
            configs.append("""
provider "google" {
  project = var.gcp_project_id
  region  = var.gcp_region
}
""")
        
        return "\n".join(configs)
    
    def _generate_network_config(self, requirements: Dict[str, Any]) -> str:
        """Generate network configuration"""
        return """
# VPC
resource "aws_vpc" "main" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name = "${var.project_name}-vpc"
  }
}

# Internet Gateway
resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
  
  tags = {
    Name = "${var.project_name}-igw"
  }
}

# Public Subnets
resource "aws_subnet" "public" {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index)
  availability_zone = var.availability_zones[count.index]
  
  map_public_ip_on_launch = true
  
  tags = {
    Name = "${var.project_name}-public-${count.index + 1}"
  }
}

# Private Subnets
resource "aws_subnet" "private" {
  count             = length(var.availability_zones)
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(var.vpc_cidr, 8, count.index + length(var.availability_zones))
  availability_zone = var.availability_zones[count.index]
  
  tags = {
    Name = "${var.project_name}-private-${count.index + 1}"
  }
}

# Route Tables
resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id
  
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }
  
  tags = {
    Name = "${var.project_name}-public-rt"
  }
}

resource "aws_route_table_association" "public" {
  count          = length(var.availability_zones)
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public.id
}
"""
    
    def _generate_compute_config(self, requirements: Dict[str, Any]) -> str:
        """Generate compute resources configuration"""
        return """
# Launch Template
resource "aws_launch_template" "main" {
  name_prefix   = "${var.project_name}-lt"
  image_id      = "ami-0c02fb55956c7d316"  # Amazon Linux 2
  instance_type = var.instance_type
  
  network_interfaces {
    associate_public_ip_address = true
    security_groups             = [aws_security_group.web.id]
  }
  
  user_data = base64encode(templatefile("${path.module}/user_data.sh", {
    project_name = var.project_name
  }))
  
  tag_specifications {
    resource_type = "instance"
    tags = {
      Name = "${var.project_name}-instance"
    }
  }
}

# Auto Scaling Group
resource "aws_autoscaling_group" "main" {
  name                = "${var.project_name}-asg"
  desired_capacity    = 2
  max_size            = 5
  min_size            = 1
  target_group_arns   = [aws_lb_target_group.main.arn]
  vpc_zone_identifier = aws_subnet.public[*].id
  
  launch_template {
    id      = aws_launch_template.main.id
    version = "$Latest"
  }
  
  tag {
    key                 = "Name"
    value               = "${var.project_name}-asg"
    propagate_at_launch = true
  }
}
"""
    
    def _generate_storage_config(self, requirements: Dict[str, Any]) -> str:
        """Generate storage resources configuration"""
        return """
# S3 Bucket for application data
resource "aws_s3_bucket" "app_data" {
  bucket = "${var.project_name}-app-data-${random_string.bucket_suffix.result}"
  
  tags = {
    Name = "${var.project_name}-app-data"
  }
}

# S3 Bucket versioning
resource "aws_s3_bucket_versioning" "app_data" {
  bucket = aws_s3_bucket.app_data.id
  versioning_configuration {
    status = "Enabled"
  }
}

# S3 Bucket encryption
resource "aws_s3_bucket_server_side_encryption_configuration" "app_data" {
  bucket = aws_s3_bucket.app_data.id
  
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# Random string for bucket name
resource "random_string" "bucket_suffix" {
  length  = 8
  special = false
  upper   = false
}
"""
    
    def _generate_database_config(self, requirements: Dict[str, Any]) -> str:
        """Generate database resources configuration"""
        return """
# RDS Subnet Group
resource "aws_db_subnet_group" "main" {
  name       = "${var.project_name}-db-subnet-group"
  subnet_ids = aws_subnet.private[*].id
  
  tags = {
    Name = "${var.project_name}-db-subnet-group"
  }
}

# RDS Instance
resource "aws_db_instance" "main" {
  identifier = "${var.project_name}-db"
  
  engine         = "postgres"
  engine_version = "13.7"
  instance_class = var.db_instance_class
  
  allocated_storage     = 20
  max_allocated_storage = 100
  storage_type          = "gp2"
  storage_encrypted     = true
  
  db_name  = "aiopsdb"
  username = "admin"
  password = random_password.db_password.result
  
  vpc_security_group_ids = [aws_security_group.db.id]
  db_subnet_group_name   = aws_db_subnet_group.main.name
  
  backup_retention_period = 7
  backup_window           = "03:00-04:00"
  maintenance_window      = "sun:04:00-sun:05:00"
  
  skip_final_snapshot = true
  
  tags = {
    Name = "${var.project_name}-db"
  }
}

# Random password for database
resource "random_password" "db_password" {
  length  = 16
  special = true
}
"""
    
    def _generate_lb_config(self, requirements: Dict[str, Any]) -> str:
        """Generate load balancer configuration"""
        return """
# Application Load Balancer
resource "aws_lb" "main" {
  name               = "${var.project_name}-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = aws_subnet.public[*].id
  
  enable_deletion_protection = false
  
  tags = {
    Name = "${var.project_name}-alb"
  }
}

# Target Group
resource "aws_lb_target_group" "main" {
  name     = "${var.project_name}-tg"
  port     = 80
  protocol = "HTTP"
  vpc_id   = aws_vpc.main.id
  
  health_check {
    enabled             = true
    healthy_threshold   = 2
    interval            = 30
    matcher             = "200"
    path                = "/health"
    port                = "traffic-port"
    protocol            = "HTTP"
    timeout             = 5
    unhealthy_threshold = 2
  }
}

# Listener
resource "aws_lb_listener" "main" {
  load_balancer_arn = aws_lb.main.arn
  port              = 80
  protocol          = "HTTP"
  
  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.main.arn
  }
}
"""
    
    def _generate_security_config(self, requirements: Dict[str, Any]) -> str:
        """Generate security configuration"""
        return """
# Web Security Group
resource "aws_security_group" "web" {
  name_prefix = "${var.project_name}-web"
  vpc_id      = aws_vpc.main.id
  
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  tags = {
    Name = "${var.project_name}-web-sg"
  }
}

# ALB Security Group
resource "aws_security_group" "alb" {
  name_prefix = "${var.project_name}-alb"
  vpc_id      = aws_vpc.main.id
  
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  ingress {
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  tags = {
    Name = "${var.project_name}-alb-sg"
  }
}

# Database Security Group
resource "aws_security_group" "db" {
  name_prefix = "${var.project_name}-db"
  vpc_id      = aws_vpc.main.id
  
  ingress {
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = [aws_security_group.web.id]
  }
  
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  
  tags = {
    Name = "${var.project_name}-db-sg"
  }
}
"""
    
    def _generate_monitoring_config(self, requirements: Dict[str, Any]) -> str:
        """Generate monitoring configuration"""
        return """
# CloudWatch Log Group
resource "aws_cloudwatch_log_group" "app" {
  name              = "/aws/application/${var.project_name}"
  retention_in_days = 30
  
  tags = {
    Name = "${var.project_name}-logs"
  }
}

# CloudWatch Dashboard
resource "aws_cloudwatch_dashboard" "main" {
  dashboard_name = "${var.project_name}-dashboard"
  
  dashboard_body = jsonencode({
    widgets = [
      {
        type   = "metric"
        x      = 0
        y      = 0
        width  = 12
        height = 6
        properties = {
          metrics = [
            ["AWS/ApplicationELB", "RequestCount", "LoadBalancer", aws_lb.main.arn_suffix],
            [".", "TargetResponseTime", ".", "."],
            [".", "HealthyHostCount", ".", "."]
          ]
          period = 300
          stat   = "Sum"
          region = var.aws_region
          title  = "ALB Metrics"
        }
      }
    ]
  })
}
"""
    
    def _generate_backup_config(self, requirements: Dict[str, Any]) -> str:
        """Generate backup configuration"""
        return """
# S3 Bucket for backups
resource "aws_s3_bucket" "backups" {
  bucket = "${var.project_name}-backups-${random_string.bucket_suffix.result}"
  
  tags = {
    Name = "${var.project_name}-backups"
  }
}

# S3 Bucket versioning for backups
resource "aws_s3_bucket_versioning" "backups" {
  bucket = aws_s3_bucket.backups.id
  versioning_configuration {
    status = "Enabled"
  }
}

# S3 Bucket encryption for backups
resource "aws_s3_bucket_server_side_encryption_configuration" "backups" {
  bucket = aws_s3_bucket.backups.id
  
  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# Lifecycle policy for backups
resource "aws_s3_bucket_lifecycle_configuration" "backups" {
  bucket = aws_s3_bucket.backups.id
  
  rule {
    id     = "backup_retention"
    status = "Enabled"
    
    transition {
      days          = 30
      storage_class = "STANDARD_IA"
    }
    
    transition {
      days          = 90
      storage_class = "GLACIER"
    }
    
    expiration {
      days = 365
    }
  }
}
"""
    
    def _generate_versions_tf(self) -> str:
        """Generate versions.tf file"""
        return """
terraform {
  required_version = ">= 1.0"
  
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    random = {
      source  = "hashicorp/random"
      version = "~> 3.0"
    }
  }
}
"""
    
    def _generate_terraform_readme(self, requirements: Dict[str, Any]) -> str:
        """Generate README for Terraform configuration"""
        return f"""
# {requirements.get('project_name', 'AI Ops Platform')} Infrastructure

This Terraform configuration creates a production-ready infrastructure for the {requirements.get('project_name', 'AI Ops Platform')}.

## Architecture

- **VPC** with public and private subnets across multiple availability zones
- **Application Load Balancer** for high availability
- **Auto Scaling Group** for automatic scaling
- **RDS PostgreSQL** database with encryption
- **S3 buckets** for application data and backups
- **CloudWatch** monitoring and logging

## Prerequisites

- Terraform >= 1.0
- AWS CLI configured
- Appropriate AWS permissions

## Usage

1. Initialize Terraform:
   ```bash
   terraform init
   ```

2. Review the plan:
   ```bash
   terraform plan
   ```

3. Apply the configuration:
   ```bash
   terraform apply
   ```

## Variables

| Variable | Description | Default |
|----------|-------------|---------|
| environment | Environment name | production |
| project_name | Project name | ai-ops-platform |
| aws_region | AWS region | us-east-1 |
| vpc_cidr | VPC CIDR block | 10.0.0.0/16 |
| instance_type | EC2 instance type | t3.medium |
| db_instance_class | RDS instance class | db.t3.micro |

## Security Features

- All resources are encrypted at rest
- Security groups with minimal required access
- Private subnets for database
- CloudWatch monitoring and alerting
- Automated backups with lifecycle policies

## Cost Optimization

- Use of t3 instances for cost efficiency
- S3 lifecycle policies for storage optimization
- Auto scaling to match demand
- Reserved instances can be applied for production

## Monitoring

- CloudWatch dashboards for key metrics
- Log aggregation and retention
- Health checks and auto-recovery
- Performance monitoring and alerting
"""
    
    async def _generate_deployment_plan(self, iac_code: Dict[str, str], requirements: Dict[str, Any]) -> Dict[str, Any]:
        """Generate deployment plan"""
        return {
            "estimated_duration": "15-20 minutes",
            "phases": [
                {
                    "phase": "Network Setup",
                    "duration": "3-5 minutes",
                    "resources": ["VPC", "Subnets", "Route Tables", "Internet Gateway"]
                },
                {
                    "phase": "Security Groups",
                    "duration": "1-2 minutes",
                    "resources": ["Web Security Group", "ALB Security Group", "Database Security Group"]
                },
                {
                    "phase": "Database",
                    "duration": "5-8 minutes",
                    "resources": ["RDS Subnet Group", "RDS Instance"]
                },
                {
                    "phase": "Application Infrastructure",
                    "duration": "3-5 minutes",
                    "resources": ["Launch Template", "Auto Scaling Group", "Load Balancer"]
                },
                {
                    "phase": "Storage and Monitoring",
                    "duration": "2-3 minutes",
                    "resources": ["S3 Buckets", "CloudWatch Dashboard", "Log Groups"]
                }
            ],
            "rollback_plan": {
                "triggers": ["Database creation failure", "Load balancer setup failure", "Security group creation failure"],
                "actions": ["Destroy created resources", "Notify administrators", "Log failure details"]
            },
            "post_deployment_checks": [
                "Verify all resources are running",
                "Test load balancer health checks",
                "Validate database connectivity",
                "Check CloudWatch metrics",
                "Verify security group rules"
            ]
        }
    
    async def _extract_resources(self, iac_code: Dict[str, str], provider: IaCProvider) -> List[IaCResource]:
        """Extract resources from IaC code"""
        resources = []
        
        # Parse Terraform resources
        if provider == IaCProvider.TERRAFORM:
            main_tf = iac_code.get('main.tf', '')
            
            # Extract resource blocks
            import re
            resource_pattern = r'resource\s+"([^"]+)"\s+"([^"]+)"\s*{'
            matches = re.findall(resource_pattern, main_tf)
            
            for resource_type, resource_name in matches:
                resources.append(IaCResource(
                    name=resource_name,
                    type=resource_type,
                    provider="aws",
                    configuration={},
                    estimated_cost=0.0,
                    security_risks=[],
                    compliance_issues=[]
                ))
        
        return resources
    
    def _estimate_deployment_time(self, requirements: Dict[str, Any]) -> str:
        """Estimate deployment time based on requirements"""
        base_time = 10  # minutes
        
        # Add time for additional resources
        if 'database' in requirements:
            base_time += 5
        if 'load_balancer' in requirements:
            base_time += 3
        if 'monitoring' in requirements:
            base_time += 2
        
        return f"{base_time}-{base_time + 5} minutes"
    
    async def _validate_pulumi(self, temp_dir: str, validation_level: IaCValidationLevel) -> IaCValidationResult:
        """Validate Pulumi configuration"""
        # Placeholder for Pulumi validation
        return IaCValidationResult(
            is_valid=True,
            errors=[],
            warnings=[],
            security_issues=[],
            compliance_violations=[],
            cost_estimate=0.0,
            deployment_time="10-15 minutes"
        )
    
    async def _run_compliance_checks(self, directory: str) -> Dict[str, Any]:
        """Run compliance checks"""
        # Placeholder for compliance checks
        return {"violations": []}
    
    async def _estimate_terraform_cost(self, directory: str) -> float:
        """Estimate Terraform deployment cost"""
        # Placeholder for cost estimation
        return 150.0  # Estimated monthly cost

    async def _analyze_security(self, iac_code: Dict[str, str], provider: IaCProvider) -> Dict[str, Any]:
        """Analyze security of generated IaC"""
        security_issues = []
        compliance_violations = []
        
        # Analyze Terraform code for security issues
        if provider == IaCProvider.TERRAFORM:
            main_tf = iac_code.get('main.tf', '')
            
            # Check for common security issues
            if '0.0.0.0/0' in main_tf and 'cidr_blocks' in main_tf:
                security_issues.append({
                    "severity": "high",
                    "type": "open_security_group",
                    "description": "Security group allows access from 0.0.0.0/0",
                    "recommendation": "Restrict CIDR blocks to specific IP ranges"
                })
            
            if 'skip_final_snapshot = true' in main_tf:
                security_issues.append({
                    "severity": "medium",
                    "type": "no_final_snapshot",
                    "description": "RDS instance configured to skip final snapshot",
                    "recommendation": "Enable final snapshot for data protection"
                })
            
            if 'storage_encrypted = false' in main_tf or 'storage_encrypted' not in main_tf:
                security_issues.append({
                    "severity": "high",
                    "type": "unencrypted_storage",
                    "description": "Storage not encrypted at rest",
                    "recommendation": "Enable encryption for all storage resources"
                })
        
        return {
            "security_issues": security_issues,
            "compliance_violations": compliance_violations,
            "security_score": max(0, 100 - len(security_issues) * 10),
            "recommendations": [
                "Enable encryption for all resources",
                "Restrict security group access",
                "Enable CloudTrail logging",
                "Use private subnets for databases",
                "Enable VPC Flow Logs"
            ]
        }
    
    async def _generate_cloudformation(self, requirements: Dict[str, Any]) -> str:
        """Generate CloudFormation template"""
        return f"""
AWSTemplateFormatVersion: '2010-09-09'
Description: 'AI Ops Platform Infrastructure - Generated by AI Ops Guardian Angel'

Parameters:
  Environment:
    Type: String
    Default: {requirements.get('environment', 'production')}
    Description: Environment name
  
  ProjectName:
    Type: String
    Default: {requirements.get('project_name', 'ai-ops-platform')}
    Description: Project name
  
  InstanceType:
    Type: String
    Default: {requirements.get('instance_type', 't3.medium')}
    Description: EC2 instance type
  
  DBInstanceClass:
    Type: String
    Default: {requirements.get('db_instance_class', 'db.t3.micro')}
    Description: RDS instance class

Resources:
  # VPC
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: {requirements.get('vpc_cidr', '10.0.0.0/16')}
      EnableDnsHostnames: true
      EnableDnsSupport: true
      Tags:
        - Key: Name
          Value: !Sub '${{ProjectName}}-vpc'
        - Key: Environment
          Value: !Ref Environment

  # Internet Gateway
  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: !Sub '${{ProjectName}}-igw'

  # Attach Internet Gateway to VPC
  AttachGateway:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      VpcId: !Ref VPC
      InternetGatewayId: !Ref InternetGateway

  # Public Subnets
  PublicSubnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.1.0/24
      AvailabilityZone: !Select [0, !GetAZs '']
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub '${{ProjectName}}-public-1'

  PublicSubnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      CidrBlock: 10.0.2.0/24
      AvailabilityZone: !Select [1, !GetAZs '']
      MapPublicIpOnLaunch: true
      Tags:
        - Key: Name
          Value: !Sub '${{ProjectName}}-public-2'

  # Route Table for Public Subnets
  PublicRouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: !Sub '${{ProjectName}}-public-rt'

  # Route to Internet Gateway
  PublicRoute:
    Type: AWS::EC2::Route
    DependsOn: AttachGateway
    Properties:
      RouteTableId: !Ref PublicRouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  # Associate Public Subnets with Route Table
  PublicSubnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet1
      RouteTableId: !Ref PublicRouteTable

  PublicSubnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      SubnetId: !Ref PublicSubnet2
      RouteTableId: !Ref PublicRouteTable

  # Security Groups
  WebSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Web security group
      VpcId: !Ref VPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 22
          ToPort: 22
          CidrIp: 0.0.0.0/0
      SecurityGroupEgress:
        - IpProtocol: -1
          CidrIp: 0.0.0.0/0
      Tags:
        - Key: Name
          Value: !Sub '${{ProjectName}}-web-sg'

  # Application Load Balancer
  ApplicationLoadBalancer:
    Type: AWS::ElasticLoadBalancingV2::LoadBalancer
    Properties:
      Name: !Sub '${{ProjectName}}-alb'
      Type: application
      Scheme: internet-facing
      Subnets:
        - !Ref PublicSubnet1
        - !Ref PublicSubnet2
      SecurityGroups:
        - !Ref WebSecurityGroup

  # Target Group
  TargetGroup:
    Type: AWS::ElasticLoadBalancingV2::TargetGroup
    Properties:
      Name: !Sub '${{ProjectName}}-tg'
      Port: 80
      Protocol: HTTP
      VpcId: !Ref VPC
      HealthCheckPath: /health
      HealthCheckProtocol: HTTP
      HealthyThresholdCount: 2
      UnhealthyThresholdCount: 2
      HealthCheckIntervalSeconds: 30
      HealthCheckTimeoutSeconds: 5

  # Listener
  Listener:
    Type: AWS::ElasticLoadBalancingV2::Listener
    Properties:
      LoadBalancerArn: !Ref ApplicationLoadBalancer
      Port: 80
      Protocol: HTTP
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref TargetGroup

  # RDS Subnet Group
  DBSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupDescription: Subnet group for RDS
      SubnetIds:
        - !Ref PublicSubnet1
        - !Ref PublicSubnet2
      Tags:
        - Key: Name
          Value: !Sub '${{ProjectName}}-db-subnet-group'

  # RDS Instance
  Database:
    Type: AWS::RDS::DBInstance
    Properties:
      DBInstanceIdentifier: !Sub '${{ProjectName}}-db'
      DBInstanceClass: !Ref DBInstanceClass
      Engine: postgres
      EngineVersion: '13.7'
      AllocatedStorage: 20
      StorageType: gp2
      StorageEncrypted: true
      DBName: aiopsdb
      MasterUsername: admin
      MasterUserPassword: !Sub '{{resolve:secretsmanager:${{ProjectName}}-db-password:SecretString:password}}'
      DBSubnetGroupName: !Ref DBSubnetGroup
      VPCSecurityGroups:
        - !Ref WebSecurityGroup
      BackupRetentionPeriod: 7
      PreferredBackupWindow: '03:00-04:00'
      PreferredMaintenanceWindow: 'sun:04:00-sun:05:00'
      SkipFinalSnapshot: false
      FinalDBSnapshotIdentifier: !Sub '${{ProjectName}}-final-snapshot'
      Tags:
        - Key: Name
          Value: !Sub '${{ProjectName}}-db'

  # S3 Bucket for Application Data
  AppDataBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${{ProjectName}}-app-data-${{AWS::StackName}}'
      VersioningConfiguration:
        Status: Enabled
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      Tags:
        - Key: Name
          Value: !Sub '${{ProjectName}}-app-data'

  # CloudWatch Log Group
  AppLogGroup:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub '/aws/application/${{ProjectName}}'
      RetentionInDays: 30

Outputs:
  VPCId:
    Description: VPC ID
    Value: !Ref VPC
    Export:
      Name: !Sub '${{AWS::StackName}}-VPC-ID'

  PublicSubnetIds:
    Description: Public subnet IDs
    Value: !Join [',', [!Ref PublicSubnet1, !Ref PublicSubnet2]]
    Export:
      Name: !Sub '${{AWS::StackName}}-Public-Subnet-IDs'

  LoadBalancerDNS:
    Description: Load balancer DNS name
    Value: !GetAtt ApplicationLoadBalancer.DNSName
    Export:
      Name: !Sub '${{AWS::StackName}}-ALB-DNS'

  DatabaseEndpoint:
    Description: Database endpoint
    Value: !GetAtt Database.Endpoint.Address
    Export:
      Name: !Sub '${{AWS::StackName}}-DB-Endpoint'
"""
    
    async def _estimate_aws_cost(self, requirements: Dict[str, Any]) -> float:
        """Estimate AWS infrastructure costs"""
        total_cost = 0.0
        
        # EC2 instances
        if 'compute_instances' in requirements:
            instance_count = requirements['compute_instances'].get('count', 2)
            instance_type = requirements['compute_instances'].get('type', 't3.medium')
            hourly_cost = self._get_instance_cost(instance_type)
            monthly_cost = instance_count * hourly_cost * 730
            total_cost += monthly_cost
        
        # RDS database
        if 'database' in requirements:
            db_instance = requirements['database'].get('instance_class', 'db.t3.micro')
            db_cost = self._get_database_cost(db_instance)
            total_cost += db_cost
        
        # Load balancer
        if 'load_balancer' in requirements:
            total_cost += 16.20  # ALB cost per month
        
        # S3 storage
        if 'storage' in requirements:
            storage_gb = requirements['storage'].get('size_gb', 100)
            storage_cost = storage_gb * 0.023  # S3 standard storage
            total_cost += storage_cost
        
        return total_cost
    
    async def _estimate_azure_cost(self, requirements: Dict[str, Any]) -> float:
        """Estimate Azure infrastructure costs"""
        total_cost = 0.0
        
        # VM instances
        if 'compute_instances' in requirements:
            instance_count = requirements['compute_instances'].get('count', 2)
            instance_type = requirements['compute_instances'].get('type', 'Standard_B2s')
            # Azure B2s cost ~$0.096/hour
            monthly_cost = instance_count * 0.096 * 730
            total_cost += monthly_cost
        
        # SQL Database
        if 'database' in requirements:
            db_sku = requirements['database'].get('sku', 'Basic')
            if db_sku == 'Basic':
                total_cost += 4.90  # Basic tier cost per month
            elif db_sku == 'Standard':
                total_cost += 30.00  # Standard tier cost per month
        
        # Load balancer
        if 'load_balancer' in requirements:
            total_cost += 18.26  # Azure LB cost per month
        
        # Storage
        if 'storage' in requirements:
            storage_gb = requirements['storage'].get('size_gb', 100)
            storage_cost = storage_gb * 0.0184  # Azure blob storage
            total_cost += storage_cost
        
        return total_cost
    
    async def _estimate_gcp_cost(self, requirements: Dict[str, Any]) -> float:
        """Estimate GCP infrastructure costs"""
        total_cost = 0.0
        
        # Compute instances
        if 'compute_instances' in requirements:
            instance_count = requirements['compute_instances'].get('count', 2)
            instance_type = requirements['compute_instances'].get('type', 'e2-medium')
            # GCP e2-medium cost ~$0.0336/hour
            monthly_cost = instance_count * 0.0336 * 730
            total_cost += monthly_cost
        
        # Cloud SQL
        if 'database' in requirements:
            db_instance = requirements['database'].get('instance_class', 'db-f1-micro')
            if db_instance == 'db-f1-micro':
                total_cost += 7.50  # f1-micro cost per month
            elif db_instance == 'db-g1-small':
                total_cost += 25.00  # g1-small cost per month
        
        # Load balancer
        if 'load_balancer' in requirements:
            total_cost += 18.00  # GCP LB cost per month
        
        # Cloud Storage
        if 'storage' in requirements:
            storage_gb = requirements['storage'].get('size_gb', 100)
            storage_cost = storage_gb * 0.020  # GCP storage
            total_cost += storage_cost
        
        return total_cost
